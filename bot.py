import os
import logging
import requests
from typing import List, Dict, Optional
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# =========================
# ƒê·ªåC BI·∫æN M√îI TR∆Ø·ªúNG
# =========================
TOKEN        = os.getenv("BOT_TOKEN", "").strip()
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()
GROUP_ID     = os.getenv("GROUP_ID", "").strip()

# =========================
# LOGGING
# =========================
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger("tg-groq-bot")

def mask(s: str, keep: int = 6) -> str:
    return s[:keep] + "..." if s else ""

logger.info("Bot kh·ªüi ƒë·ªông. Token: %s", mask(TOKEN))
logger.info("Groq key: %s", mask(GROQ_API_KEY))
logger.info("Group ID: %s", GROUP_ID or "Kh√¥ng gi·ªõi h·∫°n")

# =========================
# GROQ CONFIG
# =========================
GROQ_MODELS_URL = "https://api.groq.com/openai/v1/models"
GROQ_CHAT_URL   = "https://api.groq.com/openai/v1/chat/completions"
CURRENT_MODEL: Optional[str] = None

PRIORITY_KEYWORDS = ["llama-4", "llama-3", "mistral", "gemma", "openchat", "chat"]
BLACKLIST         = ["embed", "embedding", "vision", "whisper", "tts", "audio", "moderation"]
MAX_REPLY_CHARS   = 3500

def _groq_headers() -> Dict[str, str]:
    return {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json",
    }

def fetch_available_models() -> List[str]:
    try:
        resp = requests.get(GROQ_MODELS_URL, headers=_groq_headers(), timeout=20)
        if resp.status_code != 200:
            logger.warning("L·ªói l·∫•y models: %s - %s", resp.status_code, resp.text)
            return []
        data = resp.json()
        return [m.get("id") for m in data.get("data", []) if isinstance(m, dict) and m.get("id")]
    except Exception as e:
        logger.error("L·ªói k·∫øt n·ªëi Groq: %s", e)
        return []

def pick_best_model(model_ids: List[str]) -> Optional[str]:
    filtered = [mid for mid in model_ids if not any(b in mid.lower() for b in BLACKLIST)]
    if not filtered:
        filtered = model_ids
    for kw in PRIORITY_KEYWORDS:
        for mid in filtered:
            if kw in mid.lower():
                return mid
    return filtered[0] if filtered else None

def ensure_model(force_refresh: bool = False) -> Optional[str]:
    global CURRENT_MODEL
    if CURRENT_MODEL is None or force_refresh:
        ids = fetch_available_models()
        CURRENT_MODEL = pick_best_model(ids)
        logger.info("M√¥ h√¨nh Groq: %s", CURRENT_MODEL or "Kh√¥ng t√¨m th·∫•y")
    return CURRENT_MODEL

def call_groq_chat(messages: List[Dict[str, str]], retry: bool = True) -> str:
    model = ensure_model()
    if not model:
        return "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh AI kh·∫£ d·ª•ng."

    payload = {
        "model": model,
        "messages": messages,
        "temperature": 0.6,
        "top_p": 0.9,
        "stream": False,
    }

    try:
        resp = requests.post(GROQ_CHAT_URL, headers=_groq_headers(), json=payload, timeout=30)
    except Exception as e:
        return f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi AI: {e}"

    if resp.status_code == 200:
        try:
            return resp.json()["choices"][0]["message"]["content"]
        except Exception as e:
            return f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch ph·∫£n h·ªìi AI: {e}"

    err_text = ""
    try:
        err_json = resp.json()
        err_text = err_json.get("error", {}).get("message", "") or resp.text
    except Exception:
        err_text = resp.text

    model_issue_signals = [
        "decommissioned", "no longer supported", "does not exist",
        "not found", "unknown model"
    ]
    if resp.status_code == 400 and retry and any(sig in err_text.lower() for sig in model_issue_signals):
        logger.warning("M√¥ h√¨nh b·ªã ng·ª´ng: %s ‚Üí refresh...", model)
        ensure_model(force_refresh=True)
        return call_groq_chat(messages, retry=False)

    if resp.status_code == 401:
        return "üîí API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n."
    if resp.status_code == 403:
        return "üö´ Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p m√¥ h√¨nh."
    if resp.status_code == 429:
        return "‚è≥ Qu√° gi·ªõi h·∫°n t·ªëc ƒë·ªô. Vui l√≤ng th·ª≠ l·∫°i sau."
    if resp.status_code >= 500:
        return "‚ö†Ô∏è L·ªói h·ªá th·ªëng ph√≠a AI. Vui l√≤ng th·ª≠ l·∫°i sau."
    return f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {resp.status_code}\n{err_text}"

def build_messages(user_text: str) -> List[Dict[str, str]]:
    system_prompt = (
        "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, "
        "th·ª±c d·ª•ng, ng·∫Øn g·ªçn nh∆∞ng ƒë·ªß √Ω. Khi c·∫ßn, h√£y ƒë∆∞a ra c√°c b∆∞·ªõc ho·∫∑c g·ª£i √Ω c·ª• th·ªÉ."
    )
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_text.strip()},
    ]

# =========================
# HANDLERS
# =========================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    model = ensure_model()
    msg = "‚úÖ Bot ƒë√£ online."
    msg += f"\nü§ñ M√¥ h√¨nh: {model}" if model else "\n‚ÑπÔ∏è Kh√¥ng ch·ªçn ƒë∆∞·ª£c m√¥ h√¨nh AI."
    await update.message.reply_text(msg)

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    model = ensure_model()
    await update.message.reply_text(f"ü§ñ M√¥ h√¨nh hi·ªán t·∫°i: {model or 'Ch∆∞a c√≥'}")

async def cmd_refresh_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    model = ensure_model(force_refresh=True)
    await update.message.reply_text(f"üîÑ ƒê√£ l√†m m·ªõi m√¥ h√¨nh: {model or 'Kh√¥ng t√¨m th·∫•y'}")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = str(update.effective_chat.id)
    if GROUP_ID and chat_id != GROUP_ID:
        return  # ch·ªâ ph·∫£n h·ªìi trong nh√≥m ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh

    text = (update.message.text or "").strip()
    if not text:
        return

    messages = build_messages(text)
    ai_reply = call_groq_chat(messages)
    if len(ai_reply) > MAX_REPLY_CHARS:
        ai_reply = ai_reply[:MAX_REPLY_CHARS] + "\n\n‚Ä¶(ƒë√£ r√∫t g·ªçn)"
    await update.message.reply_text(ai_reply or "‚ö†Ô∏è Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ AI.")

# =========================
# MAIN
# =========================
def main():
    ensure_model(force_refresh=True)
    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("refreshmodel", cmd_refresh_model))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    app.run_polling()

if __name__ == "__main__":
    main()
