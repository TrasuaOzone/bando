import os
import logging
import requests
import base64
import time

from typing import List, Dict, Optional
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# =========================
# Äá»ŒC TOKEN & KEY Tá»ª FILE / ENV
# =========================
def read_secret(env_key: str, file_name: str) -> Optional[str]:
    val = os.getenv(env_key, "").strip()
    if val:
        return val
    if os.path.exists(file_name):
        with open(file_name, "r", encoding="utf-8") as f:
            return f.readline().strip()
    return None

def read_text(file_name: str) -> Optional[str]:
    if os.path.exists(file_name):
        with open(file_name, "r", encoding="utf-8") as f:
            return f.readline().strip()
    return None

TOKEN          = read_secret("BOT_TOKEN", "TOKEN.txt")
GROQ_API_KEY   = read_secret("GROQ_API_KEY", "GROQ_API_KEY.txt")
GROUP_ID       = read_text("GROUP_ID.txt")
GITHUB_REPO    = read_text("GITHUB_REPO.txt")        # vÃ­ dá»¥ "owner/repo"
GITHUB_BRANCH  = read_text("GITHUB_BRANCH.txt") or "main"
GITHUB_TOKEN   = read_text("GITHUB_TOKEN.txt")
DRIVE_FOLDER_ID= read_text("DRIVE_FOLDER_ID.txt")

# =========================
# LOGGING
# =========================
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger("tg-groq-bot")

def mask(s: str, keep: int = 6) -> str:
    return s[:keep] + "..." if s else ""

logger.info("Bot khá»Ÿi Ä‘á»™ng. Token: %s", mask(TOKEN))
logger.info("Groq key: %s", mask(GROQ_API_KEY))
logger.info("Group ID: %s", GROUP_ID or "KhÃ´ng giá»›i háº¡n")
logger.info("GitHub Repo: %s | Branch: %s", GITHUB_REPO, GITHUB_BRANCH)
logger.info("Drive Folder ID: %s", DRIVE_FOLDER_ID)

# =========================
# GROQ CONFIG
# =========================
GROQ_MODELS_URL  = "https://api.groq.com/openai/v1/models"
GROQ_CHAT_URL    = "https://api.groq.com/openai/v1/chat/completions"
CURRENT_MODEL: Optional[str] = None

PRIORITY_KEYWORDS = ["llama-4", "llama-3", "mistral", "gemma", "openchat", "instruct", "chat"]
BLACKLIST         = ["embed", "embedding", "vision", "whisper", "tts", "audio", "moderation"]
MAX_REPLY_CHARS   = 3500

def _groq_headers() -> Dict[str, str]:
    return {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json",
    }

def fetch_available_models() -> List[str]:
    try:
        resp = requests.get(GROQ_MODELS_URL, headers=_groq_headers(), timeout=20)
        if resp.status_code != 200:
            logger.warning("Lá»—i láº¥y models: %s - %s", resp.status_code, resp.text)
            return []
        data = resp.json()
        return [m.get("id") for m in data.get("data", []) if isinstance(m, dict) and m.get("id")]
    except Exception as e:
        logger.error("Lá»—i káº¿t ná»‘i Groq: %s", e)
        return []

def pick_best_model(model_ids: List[str]) -> Optional[str]:
    filtered = [mid for mid in model_ids if not any(b in mid.lower() for b in BLACKLIST)]
    if not filtered:
        filtered = model_ids
    for kw in PRIORITY_KEYWORDS:
        for mid in filtered:
            if kw in mid.lower():
                return mid
    return filtered[0] if filtered else None

def ensure_model(force_refresh: bool = False) -> Optional[str]:
    global CURRENT_MODEL
    if CURRENT_MODEL is None or force_refresh:
        ids = fetch_available_models()
        CURRENT_MODEL = pick_best_model(ids)
        logger.info("MÃ´ hÃ¬nh Groq: %s", CURRENT_MODEL or "KhÃ´ng tÃ¬m tháº¥y")
    return CURRENT_MODEL

def call_groq_chat(messages: List[Dict[str, str]], retry: bool = True) -> str:
    model = ensure_model()
    if not model:
        return "âš ï¸ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh AI kháº£ dá»¥ng."

    payload = {
        "model": model,
        "messages": messages,
        "temperature": 0.6,
        "top_p": 0.9,
        "stream": False,
    }

    try:
        resp = requests.post(GROQ_CHAT_URL, headers=_groq_headers(), json=payload, timeout=30)
    except Exception as e:
        return f"âš ï¸ KhÃ´ng thá»ƒ káº¿t ná»‘i AI: {e}"

    if resp.status_code == 200:
        try:
            return resp.json()["choices"][0]["message"]["content"]
        except Exception as e:
            return f"âš ï¸ Lá»—i phÃ¢n tÃ­ch pháº£n há»“i AI: {e}"

    # Xá»­ lÃ½ lá»—i chi tiáº¿t theo status code
    err_text = ""
    try:
        err_json = resp.json()
        err_text = err_json.get("error", {}).get("message", "") or resp.text
    except Exception:
        err_text = resp.text

    # Náº¿u model decommissioned, refresh rá»“i thá»­ láº¡i 1 láº§n
    model_issue_signals = [
        "decommissioned", "no longer supported", "does not exist",
        "not found", "unknown model"
    ]
    if resp.status_code == 400 and retry and any(sig in err_text.lower() for sig in model_issue_signals):
        logger.warning("MÃ´ hÃ¬nh bá»‹ ngá»«ng: %s â†’ refresh...", model)
        ensure_model(force_refresh=True)
        return call_groq_chat(messages, retry=False)

    if resp.status_code == 401:
        return "ğŸ”’ API key khÃ´ng há»£p lá»‡ hoáº·c Ä‘Ã£ háº¿t háº¡n."
    if resp.status_code == 403:
        return "ğŸš« KhÃ´ng cÃ³ quyá»n truy cáº­p mÃ´ hÃ¬nh."
    if resp.status_code == 429:
        return "â³ QuÃ¡ giá»›i háº¡n tá»‘c Ä‘á»™. Vui lÃ²ng thá»­ láº¡i sau."
    if resp.status_code >= 500:
        return "âš ï¸ Lá»—i há»‡ thá»‘ng phÃ­a AI. Vui lÃ²ng thá»­ láº¡i sau."
    return f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {resp.status_code}\n{err_text}"

def build_messages(user_text: str) -> List[Dict[str, str]]:
    system_prompt = (
        "Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ¢n thiá»‡n, tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng, "
        "thá»±c dá»¥ng, ngáº¯n gá»n nhÆ°ng Ä‘á»§ Ã½. Khi cáº§n, hÃ£y Ä‘Æ°a ra cÃ¡c bÆ°á»›c hoáº·c gá»£i Ã½ cá»¥ thá»ƒ."
    )
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_text.strip()},
    ]

# =========================
# HÃ€M PUSH CODE LÃŠN GITHUB
# =========================
def push_to_github(path: str, repo: str, branch: str, token: str) -> (bool, str):
    with open(path, "rb") as f:
        content = base64.b64encode(f.read()).decode()
    url = f"https://api.github.com/repos/{repo}/contents/{path}"
    data = {
        "message": f"Add generated file {path}",
        "content": content,
        "branch": branch
    }
    headers = {"Authorization": f"token {token}"}
    resp = requests.put(url, json=data, headers=headers)
    if resp.status_code in (200, 201):
        file_url = resp.json()["content"]["html_url"]
        return True, file_url
    return False, f"{resp.status_code}: {resp.text}"

# =========================
# HANDLERS
# =========================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    model = ensure_model()
    msg = "âœ… Bot Ä‘Ã£ online."
    msg += f"\nğŸ¤– MÃ´ hÃ¬nh: {model}" if model else "\nâ„¹ï¸ KhÃ´ng chá»n Ä‘Æ°á»£c mÃ´ hÃ¬nh AI."
    await update.message.reply_text(msg)

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    model = ensure_model()
    await update.message.reply_text(f"ğŸ¤– MÃ´ hÃ¬nh hiá»‡n táº¡i: {model or 'ChÆ°a cÃ³'}")

async def cmd_refresh_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    model = ensure_model(force_refresh=True)
    await update.message.reply_text(f"ğŸ”„ ÄÃ£ lÃ m má»›i mÃ´ hÃ¬nh: {model or 'KhÃ´ng tÃ¬m tháº¥y'}")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    text = (update.message.text or "").strip()
    logger.info("Chat ID: %s | Text: %s", chat_id, text)

    if GROUP_ID and str(chat_id) != GROUP_ID:
        return
    if not text:
        return

    messages = build_messages(text)
    ai_reply = call_groq_chat(messages)
    if len(ai_reply) > MAX_REPLY_CHARS:
        ai_reply = ai_reply[:MAX_REPLY_CHARS] + "\n\nâ€¦(Ä‘Ã£ rÃºt gá»n)"
    await update.message.reply_text(ai_reply or "âš ï¸ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« AI.")

# Command /gen: táº¡o code, lÆ°u file, push lÃªn GitHub
async def cmd_gen(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prompt = update.message.text.replace("/gen", "").strip()
    if not prompt:
        await update.message.reply_text("â— Vui lÃ²ng thÃªm mÃ´ táº£ sau /gen")
        return

    # 1) Sinh code
    messages = build_messages(f"Write Python script for: {prompt}")
    code = call_groq_chat(messages)

    # 2) LÆ°u file táº¡m
    timestamp = int(time.time())
    fname = f"generated_{timestamp}.py"
    with open(fname, "w", encoding="utf-8") as f:
        f.write(code)

    # 3) Push lÃªn GitHub
    ok, result = push_to_github(fname, GITHUB_REPO, GITHUB_BRANCH, GITHUB_TOKEN)
    if ok:
        reply = f"âœ… ÄÃ£ push lÃªn GitHub: {result}"
    else:
        reply = f"âŒ Push tháº¥t báº¡i: {result}"
    await update.message.reply_text(reply)

# =========================
# MAIN
# =========================
def main():
    ensure_model(force_refresh=True)
    app = ApplicationBuilder().token(TOKEN).build()

    # ÄÄƒng kÃ½ handlers
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("refreshmodel", cmd_refresh_model))
    app.add_handler(CommandHandler("gen", cmd_gen))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    app.run_polling()

if __name__ == "__main__":
    main()
